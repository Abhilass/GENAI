Upon evaluating the arguments presented on both sides of the motion "There needs to be strict law to regulate AI," the side advocating for strict regulation presents a more convincing case grounded in the imperative to safeguard society from significant and well-substantiated risks. 

Their argument comprehensively outlines how AI's profound societal impact necessitates clear legal standards to prevent misuse, bias, privacy violations, and autonomous systems causing harm. The proponents effectively emphasize accountability, transparency, and the protection of human rights as core rationales, articulating that well-crafted laws can foster trust and guide innovation responsibly. Their point that legal frameworks are not inhibitors but essential safeguards aligns persuasively with the broader ethical and security concerns that AI entails.

Conversely, the opposition raises valid points about the risks of overregulation: potential stifling of innovation, bureaucratic inertia, market concentration favoring large corporations, and the difficulty lawmakers face in keeping pace with fast-moving technology. They advocate for flexible, adaptive, and self-regulatory approaches to balance ethical oversight with innovation freedom. However, these arguments, while practically insightful, underestimate the consequences of leaving AI development insufficiently regulated, particularly given the high stakes around privacy, discrimination, and safety. The assumption that self-regulation alone can ensure ethical outcomes is optimistic and lacks mechanisms for enforcement or accountability on a broad scale.

Furthermore, the "soft" regulatory approach risks regulatory gaps exploited by bad actors or rapid unchecked deployment causing harm before adaptive frameworks can react. The fear of losing global competitiveness, while not negligible, should not overshadow the fundamental need to preserve societal values and individual rights, which strict laws aim to protect.

In sum, the argument for strict AI regulation is more compelling because it directly addresses the profound challenges posed by AI, offering a clear framework to mitigate risks while still enabling responsible innovation. It recognizes that the consequences of neglecting regulation are too severe to risk laissez-faire approaches. Therefore, the side supporting strict legal regulation wins due to its robust, principled, and pragmatic rationale for ensuring AI serves as a positive force aligned with human welfare and democratic accountability.